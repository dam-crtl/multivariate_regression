{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4598b09-1080-4b92-a19f-5ab93696b651",
   "metadata": {},
   "source": [
    "# First Assingment of Pattern Recognition, Adv.\n",
    "### Masanori Tsutsumi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4c20e2-d151-46ae-9d21-8f5b6137e42c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8777d93-3442-435d-90f6-c896aeb129cd",
   "metadata": {},
   "source": [
    " I used Energey efficiency Data Set.  \n",
    " I could load this data from \"ENB2012_data.xlsx\". I found this dataset at UCI Machine Learning Repository(http://archive.ics.uci.edu/ml/index.php).\n",
    " The Energy Efficiency Dataset is the dataset on building energy efficiency that includes eight explanatory variables and two objective variables (heating and cooling loads). This dataset is mainly used to apply multivariate regression to predict building energy efficiency.\n",
    " \n",
    "This dataset consists of  \n",
    "Input variables:  \n",
    "X1 - Relative Compactness  \n",
    "X2 - Surface Area  \n",
    "X3 - Wall Area  \n",
    "X4 - Roof Area  \n",
    "X5 - Overall Height  \n",
    "X6 - Orientation  \n",
    "X7 - Glazing Area  \n",
    "X8 - Glazing Area Distribution  \n",
    "Output variables:  \n",
    "Y1 - Heating Load  \n",
    "Y2 - Cooling Load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a6616-f73c-4d1b-9659-9a78df7efae3",
   "metadata": {},
   "source": [
    "I predicted 'Heating Load' and 'Cooling Load' from 'Relative Compactness',\n",
    "'Surface Area', 'Wall Area', 'Roof Area', 'Overall Height', 'Orientation', 'Glazing Area' and 'Glazing Area Distribution'. \n",
    "First, I will use Linear Regression Model to predict Y1 and Y2. Then I will predict them by using Linear Basis Function Model with gussian basis function and grid search. Finally, I will discuss about the difference between these two models. compare these two results And I will focus on RMSE of the Linear Basis Function Model for each parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2336850a-83d2-4831-92ca-a1bc9a903f87",
   "metadata": {},
   "source": [
    "In this report, I used random choice. But I set random seed when using it. So, the result of each cell is the same no matter how many times you run the cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d7c97c-6420-4c05-955e-4d5ed96af858",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ebd750c-f11f-4fc2-9eb4-b04159142c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4779532-7181-4498-8c1e-78cc7bc8b604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     X1     X2     X3      X4   X5  X6   X7  X8     Y1     Y2\n",
      "0  0.98  514.5  294.0  110.25  7.0   2  0.0   0  15.55  21.33\n",
      "1  0.98  514.5  294.0  110.25  7.0   3  0.0   0  15.55  21.33\n",
      "2  0.98  514.5  294.0  110.25  7.0   4  0.0   0  15.55  21.33\n",
      "3  0.98  514.5  294.0  110.25  7.0   5  0.0   0  15.55  21.33\n",
      "4  0.90  563.5  318.5  122.50  7.0   2  0.0   0  20.84  28.28\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(\"ENB2012_data.xlsx\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c578c6f3-5105-477e-b4a3-13eea418e1e5",
   "metadata": {},
   "source": [
    "I loaded 'ENB2012_data.xlsx'. The five rows of this file are shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42e1adb1-4962-4cbe-8a98-5bd8e3a58073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(X, y):\n",
    "    np.random.seed(seed=32)\n",
    "    data_index = np.arange(X.shape[0])\n",
    "    np.random.shuffle(data_index)\n",
    "    return X[data_index], y[data_index]\n",
    "\n",
    "def train_test_split(X, y, test_ratio=0.2, shuffle=True):\n",
    "    if shuffle:\n",
    "        X, y = shuffle_data(X, y)\n",
    "    train_size = len(y) - int(len(y) * test_ratio)\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5e5560-a3a0-4f62-9d2f-0e239bdb09f7",
   "metadata": {},
   "source": [
    "I defined \"train_test_split\" function in the cell above. I will use this function to split the given data into training data and test data at a ratio of 0.8 to 0.2. I will use the training dataset to train models and test dataset to evaluate the accuracy of prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2421ce9e-a8ec-4ac1-949b-18cc5e6af355",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df[['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8']].values, df[['Y1', 'Y2']].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10afc8ac-00e3-4638-bda5-bb415329f8e7",
   "metadata": {},
   "source": [
    "I divided the data into training data and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f14ce19-4929-4e5d-8721-a8eae3944d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_rmse(y_true, y_pred):\n",
    "    mse = np.mean((y_true - y_pred)**2, axis=0)\n",
    "    rmse = np.sqrt(mse)\n",
    "    avg_rmse = np.mean(rmse)\n",
    "    return round(avg_rmse, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f10a45-107e-4695-b761-e3dd06fc0a83",
   "metadata": {},
   "source": [
    "I defined Root Mean Square Error(RMSE) function to evaluate how accurately the model fit to the datasets.  \n",
    "Here, considering these kind of samples,\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\text{input} : \\textbf{x}_i = (x_{i1}, x_{i2},...,x_{iD}) (i = 1, 2,...,N)\\\\\n",
    "\\text{the number of samples} : N\\\\\n",
    "\\text{output} : \\textbf{t}_i = (t_{i1}, t_{i2},...,t_{ip}) (i = 1, 2,...,N)\\\\\n",
    "\\end{equation*}\n",
    "$$\n",
    "RMSE for multiple output can calculated as\n",
    "$$\n",
    "\\text{RMSE} = \\frac{1}{p} \\sum_{i=1}^{p} \\sqrt{\\frac{1}{N} \\sum_{j=1}^{N}(\\hat{t}_{ji} - t_{ji})^2}\n",
    "$$\n",
    "First, I will predict the target variables by using Linear Regression Model.  \n",
    "when the design matrix $X$ and target variables $\\textbf{t}$ are  \n",
    "$$\n",
    "     X = \\begin{pmatrix}\\\n",
    "1 & x_{11} & x_{12} & \\cdots & x_{1D}\\\\\n",
    "1 & x_{21} & x_{22} & \\cdots & x_{2D}\\\\\n",
    "\\vdots & & \\ddots & \\vdots\\\\\n",
    "1& x_{N1} & x_{N2} & \\cdots & x_{ND}\\\\\n",
    "\\end{pmatrix}, \n",
    "\\begin{equation*}\n",
    "\\textbf{t} = \\begin{pmatrix}\n",
    "t_{11} & t_{12} & \\cdots & t_{1p}\\\\\n",
    "t_{21} & t_{22} & \\cdots & t_{2p}\\\\\n",
    "\\vdots & & \\ddots & \\vdots\\\\\n",
    "t_{N1} & t_{N2} & \\cdots & t_{Np}\\\\\n",
    "\\end{pmatrix}\\\\\n",
    "\\end{equation*}\n",
    "$$\n",
    "We can find the optimized weights of Linear Regression Models $W^*$  \n",
    "$$\n",
    "W^* = (X^T X)^{-1}X^T \\textbf{t}\n",
    "$$ \n",
    "Then, predicted target objectives $\\hat{\\textbf{t}}$ is calculated.\n",
    "$$\n",
    "\\hat{\\textbf{t}} = XW^*\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96ef17ec-8009-46bf-96a9-38d2a9ca5194",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegressionModel:\n",
    "    def __init__(self):\n",
    "        self.weights = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_hat = np.concatenate((np.ones((len(X), 1)), X), axis = 1)\n",
    "        self.weights = np.linalg.inv(X_hat.T @ X_hat) @ X_hat.T @ y\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_hat2 = np.concatenate((np.ones((len(X), 1)), X), axis = 1)\n",
    "        y_pred =  X_hat2 @ self.weights\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eee7254-fe6d-4a20-84ba-ef2e3c26e079",
   "metadata": {},
   "source": [
    "I implemented MaltivariateLinearRegressionModel class.\n",
    "First, I will predict the target variables by using it.  \n",
    "After that, I will use Linear Basis Function Model with gaussian basis function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42095340-f4a7-4844-ad00-3d4eaf8790bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_basis_function(x, mu, s):\n",
    "    return np.exp(-np.sum((x - mu)**2)/(2*s**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073c2a2e-cb9e-430d-b269-5f16800ff6f1",
   "metadata": {},
   "source": [
    "gaussian basis function\n",
    "$$\n",
    "\\phi_j(x)=\\exp\\left(-\\frac{||x-\\mu_j||_2^2}{2s_j^2}\\right)\n",
    "$$\n",
    "here  \n",
    "$x$ : input (vector)  \n",
    "$\\mu_j$ : mean (vector)  \n",
    "$s_j$ : standard deviation (scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832bb869-8458-4911-8a7f-5364588003cc",
   "metadata": {},
   "source": [
    "I will use gaussian basis function for Linear Basis Function Model. The inputs are the observation, mean values and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a0b0ba2-3251-40e4-a7c9-67c94c0c2534",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_basis_functions = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd0ca089-30b6-46b7-bde3-5da3d2da3c35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LinearBasisFunctionModel:\n",
    "    def __init__(self, basis_function, num_basis_functions, mu, s):\n",
    "        self.basis_function = basis_function\n",
    "        self.num_basis_functions = num_basis_functions\n",
    "        self.mu = mu\n",
    "        self.s = s\n",
    "        self.weights = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        design_matrix = np.ones((len(X), self.num_basis_functions + 1))\n",
    "        for i in range(self.num_basis_functions):\n",
    "            for j in range(len(X)):\n",
    "                design_matrix[j, i + 1] = np.array(self.basis_function(X[j], self.mu[i], self.s[i]))\n",
    "        self.weights = np.linalg.inv(design_matrix.T @ design_matrix) @ design_matrix.T @ y\n",
    "        \n",
    "    def predict(self, X):\n",
    "        y_pred = np.empty((len(X), 2))\n",
    "        for i in range(len(X)):\n",
    "            y_pred[i] = self.weights[0] + sum(self.weights[j + 1] * self.basis_function(X[i], self.mu[j], self.s[j]) for j in range(self.num_basis_functions))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf5634e-c2d5-4dec-a39d-926e4dbce100",
   "metadata": {},
   "source": [
    "In the cell above, I coded LinearBasisFunctionModel class.  \n",
    "The initial inputs are basis function, the number of basis functions, the matrix of the mean set and the vector of standard deviation set which is used to calculate basis functions.  \n",
    "To find the weights $W^*$, I used the design matrix as $\\Phi$.  \n",
    "$$\\Phi = \\begin{pmatrix}\n",
    "\\phi_{0}(x_1) & \\phi_{1}(x_1) & \\cdots & \\phi_{M-1}(x_1)\\\\\n",
    "\\phi_{0}(x_2) & \\phi_{1}(x_2) & \\cdots & \\phi_{M-1}(x_2)\\\\\n",
    "\\vdots & & \\ddots & \\vdots\\\\\n",
    "\\phi_{0}(x_N) & \\phi_{1}(x_N) & \\cdots & \\phi_{M-1}(x_N)\\\\\n",
    "\\end{pmatrix}\\\\\n",
    "\\phi_{0}(x_i) = 1, (i = 1, 2,..., N)\n",
    "$$\n",
    "\n",
    "\n",
    "In this report, I will fix $M$ to 5.  \n",
    "Let $\\textbf{t}$ be the target variable.  \n",
    "when optimizing weights, the calculation is like the following equation.\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "W^* = (\\Phi^T\\Phi)^{-1}\\Phi^T \\textbf{t}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "\n",
    "By using calculated weights $W^*$, I will predict Y1 and Y2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856b65e1-2753-4d0c-af2d-6eba7d610df4",
   "metadata": {},
   "source": [
    "When using Gaussian Basis Function, I have to decide the values of mu and s. In this report, I will generate three types of mu matrices which is composed of the randomly chosen integers between 10 and 100. And I also generate three types of s vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68674329-7bb8-49b8-a254-5dff278fdfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu[0] = [[38 21 23 33 96 38 42 79]\n",
      " [21 45 43 15 26 21 64 56]\n",
      " [52 71 55 89 64 86 73 49]\n",
      " [32 81 49 17 73 30 44 53]]\n",
      "mu[1] = [[88 94 84 74 69 73 75 92]\n",
      " [16 35 96 25 95 36 10 48]\n",
      " [40 59 19 97 27 84 35 99]\n",
      " [20 23 75 56 69 22 30 85]]\n",
      "mu[2] = [[52 19 26 32 22 38 77 65]\n",
      " [58 40 71 42 83 87 59 69]\n",
      " [67 65 69 69 64 55 17 94]\n",
      " [17 42 27 22 24 40 23 46]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(52)\n",
    "mu = np.array([np.random.randint(10, 100, 8 * 4 * 3)]).reshape(3, 4, 8)\n",
    "for i in range(len(mu)):\n",
    "    print(\"mu[{0}] = {1}\".format(i, mu[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb693ac4-ccd7-4700-91c1-8ce9ef75d585",
   "metadata": {},
   "source": [
    "I will use these three types of mu for grid search. Then I will generate the candidates of stadard deviation s. I will create an array with as many elements as the number of basis functions with a positive integer as the first term and common difference for each candidate. This time, I choosed 30, 40, 50 as the candidates of the positive integer and they are correspond to s[0], s[1], s[2], respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30d6a27d-bd12-40f2-b6bf-4f7d6bbde876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s[0]=[ 30.  60.  90. 120.]\n",
      "s[1]=[ 40.  80. 120. 160.]\n",
      "s[2]=[ 50. 100. 150. 200.]\n"
     ]
    }
   ],
   "source": [
    "s = np.empty((3, 4))\n",
    "l = [30, 40, 50]\n",
    "for i in range(len(l)):\n",
    "    s[i] = np.array([j * l[i] for j in range(1, num_basis_functions+1)])\n",
    "    print('s[{0}]={1}'.format(i, s[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e05ae9-40c9-4671-aa91-e5186dfe6658",
   "metadata": {},
   "source": [
    "I created the candidates of standard deviation set.\n",
    "I will also use these three types of s and do a grid search on mu and s.\n",
    "Then I will calculate RMSE and compare the best RSME of Linear Basis Function Model with that of Linear Regression Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1643517e-1c9b-47df-ba3d-95725d4934e6",
   "metadata": {},
   "source": [
    "## Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8f9932-cdd5-4741-a89c-6ab5d23089ac",
   "metadata": {},
   "source": [
    "First, I will predict Y1 and Y2 by using Linear Regression Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09b3ecff-5bb4-481a-ba7b-2af0b1869be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSME: 66.7359\n"
     ]
    }
   ],
   "source": [
    "linear_model = MultivariateLinearRegressionModel()\n",
    "linear_model.fit(X_train, y_train)\n",
    "y_pred = linear_model.predict(X_test)\n",
    "print('RSME: {}'.format(multi_rmse(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889b7bf9-8541-426a-829c-ae42eeed7198",
   "metadata": {},
   "source": [
    "Second, I will predict Y1 and Y2 by using Linear Regression Model and grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3a5a663-edb0-40b8-b8fe-7eefe5b061d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSME (mu[0], s[0]): 8.1959\n",
      "RSME (mu[0], s[1]): 7.1318\n",
      "RSME (mu[0], s[2]): 6.7866\n",
      "RSME (mu[1], s[0]): 7.9594\n",
      "RSME (mu[1], s[1]): 6.8672\n",
      "RSME (mu[1], s[2]): 6.3965\n",
      "RSME (mu[2], s[0]): 8.2712\n",
      "RSME (mu[2], s[1]): 7.4553\n",
      "RSME (mu[2], s[2]): 7.1126\n",
      "the lowest RMSE is 6.3965\n",
      "the highest RMSE is 8.2712\n"
     ]
    }
   ],
   "source": [
    "l = []\n",
    "for i in range(mu.shape[0]):\n",
    "    for j in range(s.shape[0]):\n",
    "        model_gaussian = LinearBasisFunctionModel(gaussian_basis_function, num_basis_functions, mu[i], s[j])\n",
    "        model_gaussian.fit(X_train, y_train)\n",
    "        y_pred = model_gaussian.predict(X_test)\n",
    "        print('RSME (mu[{0}], s[{1}]): {2}'.format(i, j, multi_rmse(y_pred, y_test)))\n",
    "        l.append(multi_rmse(y_pred, y_test))\n",
    "\n",
    "print('the lowest RMSE is {}'.format(min(l)))\n",
    "print('the highest RMSE is {}'.format(max(l)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78b1ede-120d-48f1-8e88-cccbd2106b0d",
   "metadata": {},
   "source": [
    "## Disscusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15e880b-098f-40b9-9af7-881deb6f026c",
   "metadata": {},
   "source": [
    "#### RMSE of Linear Basis Function Model vs. RMSE of Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9cb759-064c-4e6b-97bc-c527fca4fafc",
   "metadata": {},
   "source": [
    " Accoding to the experiment, the lowest RMSE of Linear Basis Regression was 6.3965. I will consider this value as the RMSE of gaussian-based Linear Basis Regression. And the RMSE of Linear Regression Model was 66.7359.  \n",
    " When comparing the RMSE of Linear Regression Model and Linear Basis Regression Model, the RMSE of Linear Basis Function Model is much lower than that of Linear Regression Model. Even when considering the highest RMSE of Linear Basis Regression Model, the value is 8.2712. So, it can be said that Linear Basis Regression Model fits better than Linear Regression Model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70081ed8-3026-4091-92d5-bb1ddbed112f",
   "metadata": {},
   "source": [
    "#### Differences in RMSE based on differences in standard deviation of linear basis function models using Gaussian basis functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175fa74a-2734-4703-9b95-621772cbcaa7",
   "metadata": {},
   "source": [
    "Next I will focus on RSME values of Linear Basis Fucntion Model. I did a grid search, so I will compare the RMSE of each condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afa10653-bc66-4581-a006-35f61932bb31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.array(l).reshape(3, 3).T\n",
    "num_sample = data.shape[0]\n",
    "num_item_per_sample = data.shape[1]\n",
    "\n",
    "width = 0.15\n",
    "margin = 0.25\n",
    "block = width * num_sample + margin\n",
    "ind = np.arange(num_item_per_sample) * block\n",
    "xlabels = [\"mu[0]\", \"mu[1]\", \"mu[2]\"]\n",
    "legendary_labels = [\"s[0]\", \"s[1]\", \"s[2]\"]\n",
    "colors = [\"red\", \"green\", \"blue\"]\n",
    "\n",
    "for i in range(num_sample):\n",
    "    plt.bar(ind + width * i, data[i], width, color=colors[i], label=legendary_labels[i])\n",
    "\n",
    "xlocs = ind + width * num_sample / 2.\n",
    "plt.xticks(xlocs, xlabels)\n",
    "plt.xlim(-margin, ind[-1] + width * num_sample + margin)\n",
    "plt.ylim(0, 14)\n",
    "plt.ylabel('RSME')\n",
    "plt.title('RSME of each mu matrix and s vector')\n",
    "plt.legend(prop={'size' : 12},loc=\"upper right\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccb9a94-f0e7-4e43-aded-f7742a8e7c03",
   "metadata": {},
   "source": [
    "The figure above shows that the values of RSME decrease as the integer of the first term of s vector bacomes big in all mu. From this fact, it is assumed that setting the parameter of standard deviation of gaussian basis function big is better for fitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ef5696-74f3-4706-b939-5046ec072d14",
   "metadata": {},
   "source": [
    "## conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4116fd9-1949-4fd9-a1a0-efb6bd7a57c7",
   "metadata": {},
   "source": [
    "In this report, I compared the RMSE of the Linear Regression Model with that of Linear Basis Function Model with gaussian basis function by using \"Energey efficiency Data Set\".\n",
    "The above experiment and discussion revealed the following\n",
    "* Linear Basis Function Regression with gaussian basis functions fits better than Linear Regression Model.\n",
    "* In this dataset, it may be better to set the parameters of standard deviation of gaussian basis function big when using Linear Basis Function Model with gaussian basis function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9b4e27-1ce7-44c2-904e-f7b334b52b49",
   "metadata": {},
   "source": [
    "## reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23827f8-505f-4ebf-8753-842429c49310",
   "metadata": {},
   "source": [
    "1. \"Understanding Gaussian Basis function parameters to be used in linear regression\", Cross Validated, url: https://stats.stackexchange.com/questions/117556/understanding-gaussian-basis-function-parameters-to-be-used-in-linear-regression/120126#120126, May, 9, 2023 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
